{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLO Object Detection with OpenCV\n",
        "\n",
        "This tutorial fully shows how to use YOLOv3 to perform Object detection on images. This tutorial will demonstrate how to load YOLO, the pretrained weights, and draw bounding boxes on the images.\n",
        "\n",
        "## Imports\n",
        "We will not be using the GPU in this lab since we are working with very few images. We also will not use Pytorch but instead OpenCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hEahF-lQi0so"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading YOLO model\n",
        "We need to load the YOLO network in OpenCV. In this assignment, we will not be re-training the network so we also need to download the weights. Please follow the instructions in the README to see the command to download the weights. To load the network, we also need a config file which is provided in this repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGCX42HPku36",
        "outputId": "23d27cc3-cb3d-4333-c33d-1ddbdb724334"
      },
      "outputs": [],
      "source": [
        "network = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
        "layers = network.getLayerNames()\n",
        "yolo_layers = [layers[i[0] - 1] for i in network.getUnconnectedOutLayers()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load an Image\n",
        "We now need to load an image to perform the task on. We will read the image using OpenCV ```imread()```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i-rRUutkzbR",
        "outputId": "9c4002de-56e7-4f6f-9d2c-7d57dcb23e81"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "image = cv2.imread('sample.jpg')\n",
        "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert Image to Blob\n",
        "We need to change the image into a 'blob', which is the input of the network. A blob is a 4D numpy array object (images, channels, width, height).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2Jkohr2oyNl",
        "outputId": "6a5aacb9-21b9-456e-d8bc-902ec37c13d4"
      },
      "outputs": [],
      "source": [
        "input_blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pass image through the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNuYVwAHnY4K",
        "outputId": "6f5bb1e0-5482-49fc-d458-6420b352f3e0"
      },
      "outputs": [],
      "source": [
        "network.setInput(input_blob)\n",
        "output = network.forward(yolo_layers)\n",
        "\n",
        "print(type(output))  # <class 'list'>\n",
        "print(type(output[0]))  # <class 'numpy.ndarray'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Variables for drawing on image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "fyXBZqHnnesj"
      },
      "outputs": [],
      "source": [
        "bounding_boxes = []\n",
        "confidences = []\n",
        "classes = []\n",
        "probability_minimum = 0.5\n",
        "threshold = 0.3\n",
        "h, w = image.shape[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get bounding boxes, confidences, and classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "DZhuIGA6nkZi"
      },
      "outputs": [],
      "source": [
        "for result in output:\n",
        "    for detection in result:\n",
        "        scores = detection[5:]\n",
        "        class_current = np.argmax(scores)\n",
        "        confidence_current = scores[class_current]\n",
        "        if confidence_current > probability_minimum:\n",
        "            box_current = detection[0:4] * np.array([w, h, w, h])\n",
        "            x_center, y_center, box_width, box_height = box_current.astype('int')\n",
        "            x_min = int(x_center - (box_width / 2))\n",
        "            y_min = int(y_center - (box_height / 2))\n",
        "            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
        "            confidences.append(float(confidence_current))\n",
        "            classes.append(class_current)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Draw bounding boxes and information on image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "PRtGYXZZnvre"
      },
      "outputs": [],
      "source": [
        "results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
        "coco_labels = 80\n",
        "np.random.seed(42)\n",
        "colours = np.random.randint(0, 255, size=(coco_labels, 3), dtype='uint8')\n",
        "\n",
        "if len(results) > 0:\n",
        "    for i in results.flatten():\n",
        "        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
        "        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
        "        colour_box = [int(j) for j in colours[classes[i]]]\n",
        "        cv2.rectangle(image, (x_min, y_min), (x_min + box_width, y_min + box_height),\n",
        "                      colour_box, 5)\n",
        "        text_box = 'conf: {:.4f}'.format(confidences[i])\n",
        "        cv2.putText(image, text_box, (x_min, y_min - 7), cv2.FONT_HERSHEY_SIMPLEX, 1.5, colour_box, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "MuUZTD-Pn1E3",
        "outputId": "cfcd99b0-586f-4bb4-e918-d5053ee28653"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "PA1_solution.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
